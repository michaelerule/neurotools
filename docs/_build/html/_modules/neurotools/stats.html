<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>neurotools.stats &mdash; Neurotools 2 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Neurotools
            <img src="../../_static/logo1.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Subpackages:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.signal.html">signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.stats.html">stats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.spatial.html">spatial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.spikes.html">spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.graphics.html">graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.linalg.html">linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.jobs.html">jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neurotools.jobs.html">util</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neurotools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>neurotools.stats</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for neurotools.stats</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/python</span>
<span class="c1"># -*- coding: UTF-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Statistical routines.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">with_statement</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">nested_scopes</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">generators</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">unicode_literals</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">scipy.stats.stats</span> <span class="kn">import</span> <span class="n">describe</span>
<span class="kn">from</span> <span class="nn">neurotools.util.tools</span> <span class="kn">import</span> <span class="n">find</span>

<div class="viewcode-block" id="nrmse"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.nrmse">[docs]</a><span class="k">def</span> <span class="nf">nrmse</span><span class="p">(</span><span class="n">estimate</span><span class="p">,</span><span class="n">true</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Normalized root mean-squared error.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimate : array-like</span>
<span class="sd">        Estimated data values</span>
<span class="sd">    true: array-like</span>
<span class="sd">        True data values</span>
<span class="sd">        </span>
<span class="sd">    Other Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    axis: int; default None</span>
<span class="sd">        Array axis along which to operate.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result: np.float64</span>
<span class="sd">        Root-mean-squared error between</span>
<span class="sd">        `estiamte` and `true`, normalized by the variance</span>
<span class="sd">        of `true`.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">X1</span><span class="p">,</span><span class="n">X2</span> <span class="o">=</span> <span class="n">estimate</span><span class="p">,</span><span class="n">true</span>
    <span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">v2</span><span class="o">**-</span><span class="mf">0.5</span><span class="c1">#(v2*v2)**-0.25</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">X1</span><span class="o">-</span><span class="n">X2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="o">*</span><span class="n">normalize</span></div>

<div class="viewcode-block" id="weighted_avg_and_std"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.weighted_avg_and_std">[docs]</a><span class="k">def</span> <span class="nf">weighted_avg_and_std</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the weighted average and standard deviation.</span>
<span class="sd">    values, weights -- Numpy ndarrays with the same shape.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    values: np.array</span>
<span class="sd">        Array of values for which to compute (μ,σ)</span>
<span class="sd">        weighted summary statistics</span>
<span class="sd">    weights: np.array</span>
<span class="sd">        Weights for each value        </span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mean: np.float64</span>
<span class="sd">        Weighted mean</span>
<span class="sd">    sigma: np.float64</span>
<span class="sd">        Weighted standard deviation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">average</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">values</span><span class="o">-</span><span class="n">average</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">average</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span></div>

<div class="viewcode-block" id="partition_data"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.partition_data">[docs]</a><span class="k">def</span> <span class="nf">partition_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">NFOLD</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Parrition independent variables `x`</span>
<span class="sd">    and dependent variables `y` into `NFOLD` </span>
<span class="sd">    crossvalidation training/testing datasets.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: np.array</span>
<span class="sd">        Independent variables</span>
<span class="sd">    y: np.array</span>
<span class="sd">        Dependent variables</span>
<span class="sd">    </span>
<span class="sd">    Other Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    NFOLD: int; default 3</span>
<span class="sd">        Number of crossvalidation blocks to partition </span>
<span class="sd">        data into. </span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result: iterator </span>
<span class="sd">        Iterator with `NFOLD` items, each element yielding: </span>
<span class="sd">            xtrain: training data for `x` for this block</span>
<span class="sd">            ytrain: training data for `y` for this block</span>
<span class="sd">            xtest: testing data for `x` for this block</span>
<span class="sd">            ytest: testing data for `y` for this block</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">partition_trials_for_crossvalidation</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">NFOLD</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;object&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NFOLD</span><span class="p">):</span>
        <span class="n">train</span>  <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">groups</span><span class="p">[[</span><span class="o">*</span><span class="p">({</span><span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">NFOLD</span><span class="p">)}</span><span class="o">-</span><span class="p">{</span><span class="n">i</span><span class="p">})]]))</span>
        <span class="n">test</span>   <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">groups</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">xtrain</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="n">train</span><span class="p">]</span>
        <span class="n">ytrain</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span><span class="n">train</span><span class="p">]</span>
        <span class="n">xtest</span>  <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="n">test</span><span class="p">]</span>
        <span class="n">ytest</span>  <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span><span class="n">test</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span></div>

<div class="viewcode-block" id="partition_trials_for_crossvalidation"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.partition_trials_for_crossvalidation">[docs]</a><span class="k">def</span> <span class="nf">partition_trials_for_crossvalidation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">K</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Split trial data into crossvalidation blocks.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : list</span>
<span class="sd">        List of trial data to partition. Each entry in the list should</span>
<span class="sd">        be a Ntimepoints x Ndatapoints array.</span>
<span class="sd">    K : int</span>
<span class="sd">        Number of crossvalidation blocks to compute</span>
<span class="sd">    shuffle : bool, default False</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    spans : list</span>
<span class="sd">        List of trial indecies to use for each block</span>
<span class="sd">        </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Number of trials</span>
    <span class="n">N</span>    <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">K</span><span class="o">&gt;</span><span class="n">N</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;#xval-blocks K=</span><span class="si">%d</span><span class="s1">&gt;#trials N=</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>
    <span class="c1"># Length of each trial</span>
    <span class="n">lens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
    <span class="c1"># Total length of the data</span>
    <span class="n">L</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lens</span><span class="p">)</span>
    <span class="c1"># Average target length of each block</span>
    <span class="n">B</span>    <span class="o">=</span> <span class="n">L</span><span class="o">/</span><span class="n">K</span>
    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="c1"># Randomly re-order the trials</span>
        <span class="n">order</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">lens</span>     <span class="o">=</span> <span class="n">lens</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>
        <span class="n">indecies</span> <span class="o">=</span> <span class="n">order</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Use trials in order</span>
        <span class="n">indecies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="c1"># Handle this one as a special case</span>
    <span class="k">if</span> <span class="n">K</span><span class="o">==</span><span class="n">N</span><span class="p">:</span>
        <span class="c1"># leave-one-out crossvalidation</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indecies</span><span class="p">])</span>
    <span class="c1"># Cumulative length of data so far including length of current trial</span>
    <span class="n">C</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">lens</span><span class="p">)</span>
    <span class="c1"># Target total cumulative length of each block</span>
    <span class="n">Bk</span>   <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">B</span>
    <span class="c1"># Edges between blocks: try to keep things close to the desired</span>
    <span class="c1"># length. </span>
    <span class="n">edge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">C</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span><span class="o">-</span><span class="n">Bk</span><span class="p">[</span><span class="kc">None</span><span class="p">,:]),</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">edge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">edge</span><span class="p">))))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span><span class="o">!=</span><span class="n">K</span><span class="p">:</span>
        <span class="c1"># Sometimes this will return duplicate edges, which is</span>
        <span class="c1"># a bit of a bug. Solution? </span>
        <span class="c1"># Don&#39;t use length-based partitions in this case</span>
        <span class="n">edge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="mf">0.5</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">K</span><span class="o">+</span><span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">edge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">edge</span><span class="p">))))</span>
    <span class="c1"># Get start and end point for each edge, to define blocks to keep</span>
    <span class="n">a</span>      <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">b</span>      <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">edge</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,[</span><span class="n">N</span><span class="p">]])</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">indecies</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ai</span><span class="p">,</span><span class="n">bi</span><span class="p">)]</span> <span class="k">for</span> <span class="n">ai</span><span class="p">,</span><span class="n">bi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">!=</span><span class="n">K</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Could not divide N=</span><span class="si">%d</span><span class="s1"> trials into K=</span><span class="si">%d</span><span class="s1"> blocks&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">result</span></div>
    
<div class="viewcode-block" id="polar_error"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.polar_error">[docs]</a><span class="k">def</span> <span class="nf">polar_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">,</span><span class="n">units</span><span class="o">=</span><span class="s1">&#39;degrees&#39;</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;L1&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Compute error for polar measurements, </span>
<span class="sd">    wrapping the circular variable appropriately.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: array-like</span>
<span class="sd">        true valies (in degrees)</span>
<span class="sd">    hx: array-like</span>
<span class="sd">        estimated values (in degrees)</span>

<span class="sd">    Other Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    units: str, default &quot;degrees&quot;</span>
<span class="sd">        Polar units to use. Either &quot;radians&quot; or &quot;degrees&quot;</span>
<span class="sd">    mode: str, default &#39;L1&#39;</span>
<span class="sd">        Error method to use. Either &#39;L1&#39; (mean absolute error) or </span>
<span class="sd">        &#39;L2&#39; (root mean-squared error)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    err:</span>
<span class="sd">        Circularly-wrapped error</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">x</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">xh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xh</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">e</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">xh</span><span class="p">)</span>
    <span class="n">k</span>  <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;radians&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span><span class="s1">&#39;degrees&#39;</span><span class="p">:</span><span class="mi">180</span><span class="p">}[</span><span class="n">units</span><span class="p">]</span>
    <span class="n">e</span><span class="p">[</span><span class="n">e</span><span class="o">&gt;</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">k</span><span class="o">-</span><span class="n">e</span><span class="p">[</span><span class="n">e</span><span class="o">&gt;</span><span class="n">k</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;L1&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;L2&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mf">.5</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Mode should be either &quot;L1&quot; or &quot;L2&quot;&#39;</span><span class="p">)</span></div>

<span class="n">error_functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;correlation&#39;</span><span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;L2&#39;</span>         <span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">xh</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="s1">&#39;L1&#39;</span>         <span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">xh</span><span class="p">)),</span>
    <span class="s1">&#39;L1_degrees&#39;</span> <span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">polar_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;L1&#39;</span><span class="p">,</span><span class="n">units</span><span class="o">=</span><span class="s1">&#39;degrees&#39;</span><span class="p">),</span>
    <span class="s1">&#39;L2_degrees&#39;</span> <span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">polar_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span><span class="n">units</span><span class="o">=</span><span class="s1">&#39;degrees&#39;</span><span class="p">),</span>
    <span class="s1">&#39;L1_radians&#39;</span> <span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">polar_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;L1&#39;</span><span class="p">,</span><span class="n">units</span><span class="o">=</span><span class="s1">&#39;radians&#39;</span><span class="p">),</span>
    <span class="s1">&#39;L2_radians&#39;</span> <span class="p">:</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">:</span> <span class="n">polar_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">xh</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span><span class="n">units</span><span class="o">=</span><span class="s1">&#39;radians&#39;</span><span class="p">)</span>
<span class="p">}</span>

<div class="viewcode-block" id="add_constant"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.add_constant">[docs]</a><span class="k">def</span> <span class="nf">add_constant</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># if Nsamples&lt;Nfeatures:</span>
    <span class="c1">#     warnings.warn(&quot;data shape is %dx%d\n# samples &lt; # features; is data transposed?&quot;%data.shape)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected a Nsamples x Nfeatures 2D array&#39;</span><span class="p">)</span>
        <span class="n">Nsamples</span><span class="p">,</span><span class="n">Nfeatures</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># Default/old behavior from before axis argument was added</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">data</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># New behavior: allow axis to be specified</span>
        <span class="c1"># shape = np.array(data.shape)</span>
        <span class="c1"># shape[axis] = 1</span>
        <span class="c1"># return np.concatenate([data,np.ones(shape)],axis=axis)</span>
        <span class="c1"># New new behavior: allow multiple axes</span>
        <span class="n">shape</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">newshape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">newshape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">newshape</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">result</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="trial_crossvalidated_least_squares"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.trial_crossvalidated_least_squares">[docs]</a><span class="k">def</span> <span class="nf">trial_crossvalidated_least_squares</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">K</span><span class="p">,</span>
    <span class="n">regress</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reg</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">errmethod</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    predicts B from A in K-fold cross-validated blocks using linear</span>
<span class="sd">    least squares. I.e. find w such that B = Aw</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">        List of trials for independent variables; For every trial, </span>
<span class="sd">        First dimension should be time or number of samples, etc. </span>
<span class="sd">    b : vector</span>
<span class="sd">        List of trials for dependent variables</span>
<span class="sd">    K : int</span>
<span class="sd">        Number of cross-validation blocks</span>

<span class="sd">    Other Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    regress : function, optional</span>
<span class="sd">        Regression function, defaults to `np.linalg.lstsq`</span>
<span class="sd">        (if providing another function, please match the </span>
<span class="sd">        call signature of `np.linalg.lstsq`)</span>
<span class="sd">    reg : scalar, default 1e-10</span>
<span class="sd">        L2 regularization penalty</span>
<span class="sd">    shuffle : bool, default False</span>
<span class="sd">        Whether to shuffle trials before crossvalidation</span>
<span class="sd">    errmethod: String</span>
<span class="sd">        Method used to compute the error. Can be &#39;L1&#39; (mean absolute error)</span>
<span class="sd">        &#39;L2&#39; (root mean-squared error) or &#39;correlation&#39; (pearson correlation</span>
<span class="sd">        coefficient). </span>
<span class="sd">    add_constant: bool, default False</span>
<span class="sd">        Whether to append an additional constand offset feature to the</span>
<span class="sd">        data. The returned weight matrix will have one extra entry, at the</span>
<span class="sd">        end, reflecting the offset, if this is set to True. </span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    w, array-like:</span>
<span class="sd">        model coefficients x from each cross-validation</span>
<span class="sd">    bhat, array-like:</span>
<span class="sd">        predicted values of b under crossvalidation</span>
<span class="sd">    error :</span>
<span class="sd">        root mean squared error from each crossvalidation run</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">errmethod</span> <span class="ow">in</span> <span class="n">error_functions</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Error method should be one of &#39;</span><span class="o">+</span>\
                         <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">error_functions</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    
    <span class="c1"># Check shape of data</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ai</span><span class="p">)</span> <span class="k">for</span> <span class="n">ai</span> <span class="ow">in</span> <span class="n">a</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bi</span><span class="p">)</span> <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">b</span><span class="p">])</span>
    <span class="n">Ntrial</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">K</span><span class="o">&lt;=</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;# crossvalidation blocks (K) should be &gt;1&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">Ntrial</span><span class="o">&lt;</span><span class="n">K</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected more than K trials to use!&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="o">!=</span><span class="n">Ntrial</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;X and Y should have same # of trials&#39;</span><span class="p">)</span>
    <span class="n">Nsampl</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">ai</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">ai</span> <span class="ow">in</span> <span class="n">a</span><span class="p">])</span>
    
    <span class="c1"># Get typical block length</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">Nsampl</span><span class="o">//</span><span class="n">K</span> 
    
    <span class="c1"># Determine trial groups for cross-validation</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">partition_trials_for_crossvalidation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">K</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span><span class="o">!=</span><span class="n">K</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected K groups for crossvalidation!&#39;</span><span class="p">)</span>
    
    <span class="c1"># Define regression solver if none provided</span>
    <span class="k">if</span> <span class="n">regress</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">regress</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">):</span>
            <span class="n">Q</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="s1">&#39;add_constant&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;add_constant&#39;</span><span class="p">]:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">add_constant</span><span class="p">(</span><span class="n">ai</span><span class="p">)</span> <span class="k">for</span> <span class="n">ai</span> <span class="ow">in</span> <span class="n">a</span><span class="p">])</span>
    
    <span class="c1"># Iterate over each cross-validation</span>
    <span class="n">x</span>    <span class="o">=</span> <span class="p">{}</span>
    <span class="n">Bhat</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">train</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="n">groups</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>       <span class="k">if</span> <span class="n">k</span><span class="o">==</span><span class="mi">0</span> 
            <span class="k">else</span> <span class="n">groups</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">k</span><span class="o">==</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span> 
            <span class="k">else</span> <span class="n">groups</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span><span class="o">+</span><span class="n">groups</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">trainA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
        <span class="n">trainB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
        <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>   <span class="o">=</span> <span class="n">regress</span><span class="p">(</span><span class="n">trainA</span><span class="p">,</span><span class="n">trainB</span><span class="p">)</span>
        <span class="c1"># Trials might be shuffled, so we predict them one-by-one</span>
        <span class="c1"># Then assign them to their correct slot to preserve original order.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
            <span class="n">Bhat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

    <span class="c1"># Convert dictionaries to list</span>
    <span class="n">Bhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">Bhat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ntrial</span><span class="p">)])</span>
    <span class="n">x</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span>   <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>     <span class="p">])</span>

    <span class="c1"># Apply error function within each crossvalidation block</span>
    <span class="n">efn</span>  <span class="o">=</span> <span class="n">error_functions</span><span class="p">[</span><span class="n">errmethod</span><span class="p">]</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="p">[</span><span class="n">efn</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">g</span><span class="p">]),</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">Bhat</span><span class="p">[</span><span class="n">g</span><span class="p">]))</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">Bhat</span><span class="p">),</span><span class="n">errs</span></div>

<div class="viewcode-block" id="partition_data_for_crossvalidation"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.partition_data_for_crossvalidation">[docs]</a><span class="k">def</span> <span class="nf">partition_data_for_crossvalidation</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">K</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    For predicting B from A, partition both training and testing</span>
<span class="sd">    data into K-fold cross-validation blocks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">        Independent variables; First dimension should be time</span>
<span class="sd">        or number of samples, etc. </span>
<span class="sd">    b : vector</span>
<span class="sd">        dependent variables</span>
<span class="sd">    K : int</span>
<span class="sd">        Number of cross-validation blocks</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    trainA : list</span>
<span class="sd">        list of training blocks for independent variables A</span>
<span class="sd">    trainB : list</span>
<span class="sd">        list of training blocks for dependent variables B</span>
<span class="sd">    testA : list</span>
<span class="sd">        list of testing blocks for independent variables A</span>
<span class="sd">    testB : list</span>
<span class="sd">        list of testing blocks for dependent variables B</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Check shape of data</span>
    <span class="n">a</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">b</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">N</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">N</span><span class="o">&lt;</span><span class="n">h</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;1st axis of `a` must be time. is `a` transposed?&#39;</span><span class="p">)</span>
    <span class="c1"># Get typical block length</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">N</span><span class="o">//</span><span class="n">K</span>
    <span class="n">trainA</span><span class="p">,</span> <span class="n">trainB</span><span class="p">,</span> <span class="n">testA</span><span class="p">,</span> <span class="n">testB</span> <span class="o">=</span> <span class="p">[],[],[],[]</span>
    <span class="c1"># Iterate over each cross-validation</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="c1"># Start and stop of testing data range</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">k</span><span class="o">*</span><span class="n">B</span>
        <span class="n">stop</span>  <span class="o">=</span> <span class="n">start</span><span class="o">+</span><span class="n">B</span> <span class="k">if</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">N</span>
        <span class="c1"># Training data (exclude testing block)</span>
        <span class="n">trainB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="n">start</span><span class="p">,</span><span class="o">...</span><span class="p">],</span><span class="n">b</span><span class="p">[</span><span class="n">stop</span><span class="p">:,</span><span class="o">...</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">trainA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[:</span><span class="n">start</span><span class="p">,:</span>  <span class="p">],</span><span class="n">a</span><span class="p">[</span><span class="n">stop</span><span class="p">:,:</span>  <span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Testing data</span>
        <span class="n">testB</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">,</span><span class="o">...</span><span class="p">]</span>
        <span class="n">testA</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">,:</span>  <span class="p">]</span>
        <span class="k">yield</span> <span class="n">trainA</span><span class="p">,</span><span class="n">trainB</span><span class="p">,</span><span class="n">testA</span><span class="p">,</span><span class="n">testB</span></div>

<div class="viewcode-block" id="block_shuffle"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.block_shuffle">[docs]</a><span class="k">def</span> <span class="nf">block_shuffle</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">BLOCKSIZE</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Shuffle a 2D array in blocks along axis 0</span>
<span class="sd">    For example, if you provide a NTIMES × NFEATURES array,</span>
<span class="sd">    this will shuffle all features similarly in blocks along the time axis</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">BLOCKSIZE</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">BLOCKSIZE</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">T</span><span class="o">//</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">BLOCKSIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">BLOCKSIZE</span><span class="p">))</span>
    <span class="n">nblocks</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">BLOCKSIZE</span><span class="p">))</span>
    <span class="n">PAD</span> <span class="o">=</span> <span class="n">nblocks</span><span class="o">*</span><span class="n">BLOCKSIZE</span><span class="o">-</span><span class="n">T</span>
    <span class="k">if</span> <span class="n">PAD</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nblocks</span><span class="o">*</span><span class="n">BLOCKSIZE</span><span class="p">,)</span><span class="o">+</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">x2</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x2</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">nblocks</span><span class="p">,</span><span class="n">BLOCKSIZE</span><span class="p">)</span><span class="o">+</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">nblocks</span><span class="p">),</span><span class="o">...</span><span class="p">]</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">nblocks</span><span class="o">*</span><span class="n">BLOCKSIZE</span><span class="p">,)</span><span class="o">+</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">return</span> <span class="n">R</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span><span class="o">...</span><span class="p">]</span></div>

<div class="viewcode-block" id="crossvalidated_least_squares"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.crossvalidated_least_squares">[docs]</a><span class="k">def</span> <span class="nf">crossvalidated_least_squares</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">K</span><span class="p">,</span><span class="n">regress</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">reg</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span><span class="n">blockshuffle</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    predicts B from A in K-fold cross-validated blocks using linear</span>
<span class="sd">    least squares. I.e. find w such that B = Aw</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">        Independent variables; First dimension should be time</span>
<span class="sd">        or number of samples, etc. </span>
<span class="sd">    b : vector</span>
<span class="sd">        dependent variables</span>
<span class="sd">    K : int</span>
<span class="sd">        Number of cross-validation blocks</span>

<span class="sd">    Other Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    regress : function, optional</span>
<span class="sd">        Regression function, defaults to `np.linalg.lstsq`</span>
<span class="sd">        (if providing another function, please match the </span>
<span class="sd">        call signature of `np.linalg.lstsq`)</span>
<span class="sd">    reg : scalar, default 1e-10</span>
<span class="sd">        L2 regularization penalty</span>
<span class="sd">    blockshuffle : positive int or None, default None</span>
<span class="sd">        If not None, should be a positive integeter indicating the </span>
<span class="sd">        block-size in which to shuffle the input data before</span>
<span class="sd">        breaking it into cross-validation blocks.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    w, array-like:</span>
<span class="sd">        model coefficients x from each cross-validation</span>
<span class="sd">    bhat, array-like:</span>
<span class="sd">        predicted values of b under crossvalidation</span>
<span class="sd">    cc, number:</span>
<span class="sd">        correlation coefficient</span>
<span class="sd">    rms, number:</span>
<span class="sd">        root mean squared error</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Check shape of data</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">N</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">N</span><span class="o">&lt;</span><span class="n">h</span><span class="p">:</span> 
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;1st axis of `a` must be time. is `a` transposed?&#39;</span><span class="p">)</span>

    <span class="n">B</span> <span class="o">=</span> <span class="n">N</span><span class="o">//</span><span class="n">K</span> <span class="c1"># Get typical block length</span>

    <span class="c1"># Optionally shuffle data</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">blockshuffle</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">blockshuffle</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">blockshuffle</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">blockshuffle</span><span class="o">&gt;</span><span class="n">B</span><span class="o">//</span><span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Shuffle block len should be &lt;½ xvalidation block len&#39;</span><span class="p">)</span>
            <span class="n">ab</span> <span class="o">=</span> <span class="n">block_shuffle</span><span class="p">(</span><span class="n">concatenate</span><span class="p">([</span><span class="n">aa</span><span class="p">,</span><span class="n">bb</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span><span class="mi">500</span><span class="p">)</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">ab</span><span class="p">[:,:</span><span class="n">h</span><span class="p">]</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">ab</span><span class="p">[:,</span><span class="n">h</span><span class="p">:]</span>

    <span class="n">x</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">regress</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1">#def regress(trainA,trainB):</span>
        <span class="c1">#    return np.linalg.lstsq(trainA,trainB,rcond=None)[0]</span>
        <span class="k">def</span> <span class="nf">regress</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">):</span>
            <span class="n">Q</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
            
    <span class="c1"># Iterate over each cross-validation</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="c1"># Start and stop of testing data range</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">k</span><span class="o">*</span><span class="n">B</span>
        <span class="n">stop</span>  <span class="o">=</span> <span class="n">start</span><span class="o">+</span><span class="n">B</span>
        <span class="k">if</span> <span class="n">k</span><span class="o">&gt;=</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">N</span>
        <span class="c1"># Training data (exclude testing block)</span>
        <span class="n">trainB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="n">start</span><span class="p">,</span><span class="o">...</span><span class="p">],</span><span class="n">b</span><span class="p">[</span><span class="n">stop</span><span class="p">:,</span><span class="o">...</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">trainA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[:</span><span class="n">start</span><span class="p">,:</span>  <span class="p">],</span><span class="n">a</span><span class="p">[</span><span class="n">stop</span><span class="p">:,:</span>  <span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Testing data</span>
        <span class="n">testB</span>  <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">,</span><span class="o">...</span><span class="p">]</span>
        <span class="n">testA</span>  <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">,:</span>  <span class="p">]</span>
        <span class="c1"># Train regression model</span>
        <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">regress</span><span class="p">(</span><span class="n">trainA</span><span class="p">,</span><span class="n">trainB</span><span class="p">)</span>
        <span class="n">reconstructed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">testA</span><span class="p">,</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="n">predict</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">reconstructed</span><span class="p">)</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
    
    <span class="c1"># Correlation coefficient</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">b</span><span class="p">))</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">cc</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">predict</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cc</span> <span class="o">=</span> <span class="p">[</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">bi</span><span class="p">,</span><span class="n">pi</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">bi</span><span class="p">,</span><span class="n">pi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">predict</span><span class="o">.</span><span class="n">T</span><span class="p">)]</span>

    <span class="c1"># Root mean-squared error</span>
    <span class="n">rms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predict</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predict</span><span class="p">),</span><span class="n">cc</span><span class="p">,</span><span class="n">rms</span></div>

<div class="viewcode-block" id="print_stats"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.print_stats">[docs]</a><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">g</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    computes, prints, and returns</span>
<span class="sd">    mean</span>
<span class="sd">    median</span>
<span class="sd">    minimum</span>
<span class="sd">    maximum</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1">#mode = modefind.modefind(g,0)</span>
    <span class="n">mn</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">md</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">mi</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">mx</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="c1">#print(prefix,&#39;mode    %s\t%0.4f&#39;%(name,mode))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span><span class="s1">&#39;mean    </span><span class="si">%s</span><span class="se">\t</span><span class="si">%0.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="n">mn</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span><span class="s1">&#39;median  </span><span class="si">%s</span><span class="se">\t</span><span class="si">%0.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="n">md</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span><span class="s1">&#39;minimum </span><span class="si">%s</span><span class="se">\t</span><span class="si">%0.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="n">mi</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span><span class="s1">&#39;maximum </span><span class="si">%s</span><span class="se">\t</span><span class="si">%0.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="n">mx</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">mn</span><span class="p">,</span><span class="n">md</span><span class="p">,</span><span class="n">mi</span><span class="p">,</span><span class="n">mx</span></div>

<div class="viewcode-block" id="outliers"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.outliers">[docs]</a><span class="k">def</span> <span class="nf">outliers</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">side</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Reject outliers from data based on percentiles.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : ndarary</span>
<span class="sd">        1D numeric array of data values</span>
<span class="sd">    percent : number</span>
<span class="sd">        percent between 0 and 100 to remove</span>
<span class="sd">    side : str</span>
<span class="sd">        &#39;left&#39; &#39;right&#39; or &#39;both&#39;. Default is &#39;both&#39;. Remove extreme</span>
<span class="sd">        values from the left / right / both sides of the data</span>
<span class="sd">        distribution. If both, the percent is halved and removed</span>
<span class="sd">        from both the left and the right</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ndarray:</span>
<span class="sd">        Boolean array of same shape as x indicating outliers</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="s1">&#39;bool&#39;</span><span class="p">)</span>
    <span class="k">if</span>   <span class="n">side</span><span class="o">==</span><span class="s1">&#39;left&#39;</span><span class="p">:</span>
         <span class="n">remove</span> <span class="o">|=</span> <span class="n">x</span><span class="o">&lt;</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">percent</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">side</span><span class="o">==</span><span class="s1">&#39;right&#39;</span><span class="p">:</span>
         <span class="n">remove</span> <span class="o">|=</span> <span class="n">x</span><span class="o">&gt;</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">100</span><span class="o">-</span><span class="n">percent</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">side</span><span class="o">==</span><span class="s1">&#39;both&#39;</span><span class="p">:</span>
         <span class="n">remove</span> <span class="o">|=</span> <span class="n">x</span><span class="o">&lt;</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">percent</span><span class="o">*</span><span class="mf">0.5</span><span class="p">)</span>
         <span class="n">remove</span> <span class="o">|=</span> <span class="n">x</span><span class="o">&gt;</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">100</span><span class="o">-</span><span class="n">percent</span><span class="o">*</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;side must be left, right, or both&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">remove</span></div>

<div class="viewcode-block" id="reject_outliers"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.reject_outliers">[docs]</a><span class="k">def</span> <span class="nf">reject_outliers</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">side</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Reject outliers from data based on percentiles.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : ndarary</span>
<span class="sd">        1D numeric array of data values</span>
<span class="sd">    percent : number</span>
<span class="sd">        percent between 0 and 100 to remove</span>
<span class="sd">    side : str</span>
<span class="sd">        &#39;left&#39; &#39;right&#39; or &#39;both&#39;. Default is &#39;both&#39;. Remove extreme</span>
<span class="sd">        values from the left / right / both sides of the data</span>
<span class="sd">        distribution. If both, the percent is halved and removed</span>
<span class="sd">        from both the left and the right</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ndarray</span>
<span class="sd">        Values with outliers removed</span>
<span class="sd">    kept</span>
<span class="sd">        Indecies of values kept</span>
<span class="sd">    removed</span>
<span class="sd">        Indecies of values removed</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">remove</span> <span class="o">=</span> <span class="n">outliers</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">percent</span><span class="p">,</span><span class="n">side</span><span class="p">)</span>
    <span class="n">to_remove</span> <span class="o">=</span> <span class="n">find</span><span class="p">(</span><span class="n">remove</span><span class="o">==</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">to_keep</span>   <span class="o">=</span> <span class="n">find</span><span class="p">(</span><span class="n">remove</span><span class="o">==</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="n">to_keep</span><span class="p">],</span> <span class="n">to_keep</span><span class="p">,</span> <span class="n">to_remove</span></div>
    
<div class="viewcode-block" id="pca"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.pca">[docs]</a><span class="k">def</span> <span class="nf">pca</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">n_keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">rank_deficient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    w,v = pca(x,n_keep=None)</span>
<span class="sd">    Performs PCA on data x, keeping the first n_keep dimensions</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: ndarray</span>
<span class="sd">        Nsamples x Nfeatures array on which to perform PCA</span>
<span class="sd">    n_keep : int</span>
<span class="sd">        Number of principle components to retain</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    w : weights (eigenvalues)</span>
<span class="sd">    v : eigenvector (principal components)</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">rank_deficient</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">&lt;=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;There appear to be more dimensions than samples,&#39;</span><span class="o">+</span>
                             <span class="s1">&#39; input array shuld have shape Nsamples x&#39;</span><span class="o">+</span>
                             <span class="s1">&#39; Nfeatures. Set rank_deficient=True to force PCA&#39;</span><span class="o">+</span>
                             <span class="s1">&#39; with fewer samples than features.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Rank deficient is set, but input does not appear&#39;</span><span class="o">+</span>
                             <span class="s1">&#39; to be rank deficient?&#39;</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">w</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
    <span class="n">o</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">w</span><span class="p">)</span>
    <span class="n">w</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">,</span><span class="n">v</span><span class="p">[:,</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">real</span>
    <span class="k">if</span> <span class="n">n_keep</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">n_keep</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">w</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">w</span><span class="p">[:</span><span class="n">n_keep</span><span class="p">],</span><span class="n">v</span><span class="p">[:,:</span><span class="n">n_keep</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">w</span><span class="p">,</span><span class="n">v</span></div>

<div class="viewcode-block" id="covariance"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.covariance">[docs]</a><span class="k">def</span> <span class="nf">covariance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">sample_deficient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">reg</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">centered</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Covariance matrix for `Nsamples` x `Nfeatures` matrix.</span>
<span class="sd">    Data are *not* centered before computing covariance.</span>
<span class="sd">    </span>
<span class="sd"> </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Nsamples x Nfeatures array-like</span>
<span class="sd">        Array of input features</span>
<span class="sd">        </span>
<span class="sd">    Other parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    y : Nsamples x Nyfeatures array-like</span>
<span class="sd">        Array of input features</span>
<span class="sd">    sample_deficient: bool, default False</span>
<span class="sd">        Whether the data contains fewer samples than it does features. </span>
<span class="sd">        If False (the default), routine will raise a `ValueError`.</span>
<span class="sd">    reg: positive scalar, default 0</span>
<span class="sd">        Diagonal regularization to add to the covariance</span>
<span class="sd">    centered: boolean, default True</span>
<span class="sd">        Whether to subtract the means from the data before taking the</span>
<span class="sd">        covariace.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : np.array</span>
<span class="sd">        Sample covariance matrix</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">Nsamples</span><span class="p">,</span><span class="n">Nfeatures</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sample_deficient</span> <span class="ow">and</span> <span class="n">Nfeatures</span><span class="o">&gt;</span><span class="n">Nsamples</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;x should be Nsample x Nfeature where Nsamples &gt;= Nfeatures&#39;</span><span class="p">);</span>
    <span class="k">if</span> <span class="n">centered</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,:]</span>

    <span class="c1"># Covariance of x</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1">#if np.all(np.isfinite(x)): </span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">Nsamples</span>
        <span class="c1">#else:</span>
        <span class="c1">#    C = np.zeros((Nfeatures,Nfeatures))</span>
        <span class="c1">#    for i in range(Nfeatures):</span>
        <span class="c1">#        C[i,i+1:] = np.nanmean(x[:,i:i+1]*x[:,i+1:],axis=0)</span>
        <span class="c1">#    C = C+C.T</span>
        <span class="c1">#    for i in range(Nfeatures):</span>
        <span class="c1">#        C[i,i]    = np.nanvar (x[:,i])</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nfeatures</span><span class="p">)</span><span class="o">*</span><span class="n">reg</span>
        <span class="k">return</span> <span class="n">C</span><span class="o">+</span><span class="n">R</span>
    
    <span class="c1"># Cross-covariance between x and y</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">Nysamples</span><span class="p">,</span><span class="n">Nyfeatures</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">Nysamples</span><span class="o">==</span><span class="n">Nsamples</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;1st dimension of x and y (# of samples) should be the same&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">abs</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">1e-12</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cross-covariance does not support non-zero regularization&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">centered</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,:]</span>
    
    <span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">Nsamples</span>
    <span class="k">return</span> <span class="n">C</span></div>
    
            

<div class="viewcode-block" id="description"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.description">[docs]</a><span class="k">class</span> <span class="nc">description</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    quick statistical description</span>
<span class="sd">    </span>
<span class="sd">    TODO: move this to stats</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max</span><span class="p">),</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">skewness</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">kurtosis</span> <span class="o">=</span> <span class="n">describe</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># quartiles</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q1</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q3</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">median</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q2</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">75</span><span class="p">)</span>

        <span class="c1"># percentiles</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p01</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p025</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mf">2.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p05</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p10</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p90</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">90</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p95</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">95</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p975</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mf">97.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p99</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">99</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">stat</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s1">&#39; </span><span class="si">%s</span><span class="s1">=</span><span class="si">%0.2f</span><span class="s1"> &#39;</span><span class="o">%</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

<div class="viewcode-block" id="description.short"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.description.short">[docs]</a>    <span class="k">def</span> <span class="nf">short</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Abbreviated statistical summary</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">abbreviations</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;N&#39;</span><span class="p">:</span><span class="s1">&#39;N&#39;</span><span class="p">,</span>
            <span class="s1">&#39;min&#39;</span><span class="p">:</span><span class="s1">&#39;mn&#39;</span><span class="p">,</span>
            <span class="s1">&#39;max&#39;</span><span class="p">:</span><span class="s1">&#39;mx&#39;</span><span class="p">,</span>
            <span class="s1">&#39;mean&#39;</span><span class="p">:</span><span class="sa">u</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span>
            <span class="s1">&#39;variance&#39;</span><span class="p">:</span><span class="sa">u</span><span class="s1">&#39;σ²&#39;</span><span class="p">,</span>
            <span class="s1">&#39;skewness&#39;</span><span class="p">:</span><span class="s1">&#39;Sk&#39;</span><span class="p">,</span>
            <span class="s1">&#39;kurtosis&#39;</span><span class="p">:</span><span class="s1">&#39;K&#39;</span>
        <span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">stat</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">abbreviations</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">:</span><span class="si">%s</span><span class="s1"> &#39;</span><span class="o">%</span><span class="p">(</span><span class="n">abbreviations</span><span class="p">[</span><span class="n">stat</span><span class="p">],</span><span class="n">shortscientific</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>
        <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="p">)</span></div></div>
        

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<div class="viewcode-block" id="glmfit"><a class="viewcode-back" href="../../obsolete/neurotools.stats.html#neurotools.stats.glmfit">[docs]</a>    <span class="k">def</span> <span class="nf">glmfit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Wrapper for statsmodels glmfit that prepares a constant </span>
<span class="sd">        parameter and configuration options for poisson-GLM fitting.</span>
<span class="sd">        Please see the documentation for glmfit in statsmodels for</span>
<span class="sd">        more details. </span>
<span class="sd">        </span>
<span class="sd">        This method will automatically add a constant colum to the feature</span>
<span class="sd">        matrix Y</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like</span>
<span class="sd">            A nobs x k array where `nobs` is the number of observations and `k`</span>
<span class="sd">            is the number of regressors. An intercept is not included by default</span>
<span class="sd">            and should be added by the user (models specified using a formula</span>
<span class="sd">            include an intercept by default). See `statsmodels.tools.add_constant`.</span>
<span class="sd">        Y : array-like</span>
<span class="sd">            1d array of poisson counts.  This array can be 1d or 2d.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># check for and maybe add constant value to X</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">hstack</span><span class="p">([</span> <span class="n">ones</span><span class="p">((</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">])</span>

        <span class="n">poisson_model</span>   <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Poisson</span><span class="p">())</span>
        <span class="n">poisson_results</span> <span class="o">=</span> <span class="n">poisson_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">poisson_results</span><span class="o">.</span><span class="n">params</span>
        <span class="k">return</span> <span class="n">M</span></div>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;could not find statsmodels; glm routines will not work&#39;</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, M Rule.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>