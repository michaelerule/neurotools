

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>neurotools.gpu.cu.function (Michael Rule’s conflicted copy 2017-08-11) module &mdash; Neurotools 2 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700&subset=latin,cyrillic' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Neurotools 2 documentation" href="index.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="index.html" class="fa fa-home"> Neurotools</a>
        
        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="simple">
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Neurotools</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>neurotools.gpu.cu.function (Michael Rule&#8217;s conflicted copy 2017-08-11) module</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/neurotools.gpu.cu.function (Michael Rule&#39;s conflicted copy 2017-08-11).txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="neurotools-gpu-cu-function-michael-rule-s-conflicted-copy-2017-08-11-module">
<h1>neurotools.gpu.cu.function (Michael Rule&#8217;s conflicted copy 2017-08-11) module<a class="headerlink" href="#neurotools-gpu-cu-function-michael-rule-s-conflicted-copy-2017-08-11-module" title="Permalink to this headline">¶</a></h1>
<p>Contains higher order functions to make creation of GPU functions more
succinct and compact. Also contains generic routines for manipulating CUDA
source objects.</p>
<dl class="function">
<dt id="neurotools.gpu.cu.function.cpu">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">cpu</code><span class="sig-paren">(</span><em>v</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts a gpu array to respective numpy array type</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.expsub">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">expsub</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.expsub" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.ezkern">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">ezkern</code><span class="sig-paren">(</span><em>header</em>, <em>code</em>, <em>other=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#ezkern"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.ezkern" title="Permalink to this definition">¶</a></dt>
<dd><p>This is my easy kernel wrapper. This function accepts a header ( the
list of arguments ), a body ( the core of the loop ), and optionally
a block of helper function code. The core loop should reference &#8220;tid&#8221; as
the thread index variable. The distribution of threads on the GPU is
automatically managed.</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.format">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">format</code><span class="sig-paren">(</span><em>code</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#format"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.format" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a kernel source auto-formatter. It mostly just does auto-indent</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpubin">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpubin</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpubin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpubin" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify calling binary r = a op b kernels. It automates creation of the result array</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpubinaryeq">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpubinaryeq</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpubinaryeq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpubinaryeq" title="Permalink to this definition">¶</a></dt>
<dd><p>This wrapper simplified the creation of kernels executing operators
like <cite>{&#8216;+=&#8217;,&#8217;-=&#8217;,&#8217;*=&#8217;,&#8217;/=&#8217;}</cite>. That is, binary operators that assign the
result to the left operator. This is to suppliment the functionality of
PyCUDA GPUArrays, which support binary operations but always allocate a
new array to hold the result. This wrapper allows you to efficiently
execute binary operations that assign the result to one of the argument
arrays. For example, implement the GPU equivalent of <cite>+=</cite> as
<cite>gpubinaryeq(&#8216;$x+$y&#8217;)(x,y)</cite>. The result will automatically be assigned to
the first argument, x.</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpufloat">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpufloat</code><span class="sig-paren">(</span><em>v</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpufloat" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts a python list to a float array on the gpu</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpufloatmat">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpufloatmat</code><span class="sig-paren">(</span><em>M</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpufloatmat" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves a python list of lists of floats to a GPU row major packed integer matric simply by flattening the python datastructure and copying</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpufloatred">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpufloatred</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpufloatred" title="Permalink to this definition">¶</a></dt>
<dd><p>Wraps a GPUArray reduction function into a succint form operating on float arrays</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuint">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuint</code><span class="sig-paren">(</span><em>M</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuint" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts a python list to an integer array on the GPU</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuintmap">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuintmap</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpuintmap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpuintmap" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the same thing as gpumap except for integer datatypes</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuintmat">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuintmat</code><span class="sig-paren">(</span><em>M</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuintmat" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves a python list of lists of integers to a GPU row major packed integer matric simply by flattening the python datastructure and copying</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuintred">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuintred</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuintred" title="Permalink to this definition">¶</a></dt>
<dd><p>Wraps a GPUArray reduction function into a succint form operating on int arrays</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpumap">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpumap</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpumap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpumap" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify creation of b[i] = f(a[i]) map
kernels. The map function is passed in as a string representing a CUDA
expression. The dollar sign $ should denote the argument variable. A
return array is automatically constructed. For example, <cite>gpumap(&#8216;$&#8217;)</cite>
creates a clone or idenitiy kernel, so <cite>A=gpumap(&#8216;$&#8217;)(B)</cite> will assign a
copy of B to A. As a nontrivial example, a nonlinear map might function
could be created as <cite>gpumap(&#8216;1/(1+exp(-$))&#8217;)</cite></p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpumapeq">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpumapeq</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpumapeq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpumapeq" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify creation of a[i] = f(a[i]) map
kernels. The map function is passed in as a string representing a CUDA
expression. The dollar sign $ should denote the argument variable. The
result is assigned into the original array, so no new memory is
allocated. For example, gpumap(&#8216;$&#8217;)
creates a clone or idenitiy kernel, so A = gpumap(&#8216;$&#8217;)(B) will assign a
copy of B to A. As a nontrivial example, a nonlinear map might function
could be created as gpumap(&#8216;1/(1+exp(-$))&#8217;)</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpupointer">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpupointer</code><span class="sig-paren">(</span><em>gpuarr</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpupointer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the starting memory location of a GPUArray</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuscalar">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuscalar</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuscalar" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify calling binary r = a op b kernels. It automates creation of the result array</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.guessGPUType">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">guessGPUType</code><span class="sig-paren">(</span><em>arg</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#guessGPUType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.guessGPUType" title="Permalink to this definition">¶</a></dt>
<dd><p>At the moment, this returns numpy.float32 for Python floats and
numpy.int32 for python integers, and is otherwise undefined</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.kernel">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">kernel</code><span class="sig-paren">(</span><em>header</em>, <em>code</em>, <em>other=None</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>This is my easy kernel wrapper. This function accepts a header ( the
list of arguments ), a body ( the core of the loop ), and optionally
a block of helper function code. The core loop should reference &#8220;tid&#8221; as
the thread index variable. The distribution of threads on the GPU is
automatically managed.</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.printKernel">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">printKernel</code><span class="sig-paren">(</span><em>code</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#printKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.printKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>This prints out a kernel source with line numbers</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.toGPUType">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">toGPUType</code><span class="sig-paren">(</span><em>arg</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.toGPUType" title="Permalink to this definition">¶</a></dt>
<dd><p>A little wrapper to auto-cast floats/ints to respective numpy datatypes
for use on the GPU. This functionality probably exists elsewhere</p>
</dd></dl>

</div>


          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, M Rule.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>