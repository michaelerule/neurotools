
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>neurotools.gpu.cu.function module &#8212; Neurotools 2 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-neurotools.gpu.cu.function">
<span id="neurotools-gpu-cu-function-module"></span><h1>neurotools.gpu.cu.function module<a class="headerlink" href="#module-neurotools.gpu.cu.function" title="Permalink to this headline">¶</a></h1>
<p>Contains higher order functions to make creation of GPU functions more
succinct and compact. Also contains generic routines for manipulating CUDA
source objects.</p>
<dl class="function">
<dt id="neurotools.gpu.cu.function.cpu">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">cpu</code><span class="sig-paren">(</span><em>v</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts a gpu array to respective numpy array type</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.expsub">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">expsub</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.expsub" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.ezkern">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">ezkern</code><span class="sig-paren">(</span><em>header</em>, <em>code</em>, <em>other=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#ezkern"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.ezkern" title="Permalink to this definition">¶</a></dt>
<dd><p>This is my easy kernel wrapper. This function accepts a header ( the
list of arguments ), a body ( the core of the loop ), and optionally
a block of helper function code. The core loop should reference “tid” as
the thread index variable. The distribution of threads on the GPU is
automatically managed.</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.format">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">format</code><span class="sig-paren">(</span><em>code</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#format"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.format" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a kernel source auto-formatter. It mostly just does auto-indent</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpubin">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpubin</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpubin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpubin" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify calling binary r = a op b kernels. It automates creation of the result array</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpubinaryeq">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpubinaryeq</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpubinaryeq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpubinaryeq" title="Permalink to this definition">¶</a></dt>
<dd><p>This wrapper simplified the creation of kernels executing operators
like <cite>{‘+=’,’-=’,’*=’,’/=’}</cite>. That is, binary operators that assign the
result to the left operator. This is to suppliment the functionality of
PyCUDA GPUArrays, which support binary operations but always allocate a
new array to hold the result. This wrapper allows you to efficiently
execute binary operations that assign the result to one of the argument
arrays. For example, implement the GPU equivalent of <cite>+=</cite> as
<cite>gpubinaryeq(‘$x+$y’)(x,y)</cite>. The result will automatically be assigned to
the first argument, x.</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpufloat">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpufloat</code><span class="sig-paren">(</span><em>v</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpufloat" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts a python list to a float array on the gpu</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpufloatmat">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpufloatmat</code><span class="sig-paren">(</span><em>M</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpufloatmat" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves a python list of lists of floats to a GPU row major packed integer matric simply by flattening the python datastructure and copying</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpufloatred">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpufloatred</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpufloatred" title="Permalink to this definition">¶</a></dt>
<dd><p>Wraps a GPUArray reduction function into a succint form operating on float arrays</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuint">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuint</code><span class="sig-paren">(</span><em>M</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuint" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts a python list to an integer array on the GPU</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuintmap">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuintmap</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpuintmap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpuintmap" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the same thing as gpumap except for integer datatypes</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuintmat">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuintmat</code><span class="sig-paren">(</span><em>M</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuintmat" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves a python list of lists of integers to a GPU row major packed integer matric simply by flattening the python datastructure and copying</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuintred">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuintred</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuintred" title="Permalink to this definition">¶</a></dt>
<dd><p>Wraps a GPUArray reduction function into a succint form operating on int arrays</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpumap">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpumap</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpumap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpumap" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify creation of b[i] = f(a[i]) map
kernels. The map function is passed in as a string representing a CUDA
expression. The dollar sign $ should denote the argument variable. A
return array is automatically constructed. For example, <cite>gpumap(‘$’)</cite>
creates a clone or idenitiy kernel, so <cite>A=gpumap(‘$’)(B)</cite> will assign a
copy of B to A. As a nontrivial example, a nonlinear map might function
could be created as <cite>gpumap(‘1/(1+exp(-$))’)</cite></p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpumapeq">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpumapeq</code><span class="sig-paren">(</span><em>exp</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#gpumapeq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.gpumapeq" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify creation of a[i] = f(a[i]) map
kernels. The map function is passed in as a string representing a CUDA
expression. The dollar sign $ should denote the argument variable. The
result is assigned into the original array, so no new memory is
allocated. For example, gpumap(‘$’)
creates a clone or idenitiy kernel, so A = gpumap(‘$’)(B) will assign a
copy of B to A. As a nontrivial example, a nonlinear map might function
could be created as gpumap(‘1/(1+exp(-$))’)</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpupointer">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpupointer</code><span class="sig-paren">(</span><em>gpuarr</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpupointer" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the starting memory location of a GPUArray</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.gpuscalar">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">gpuscalar</code><span class="sig-paren">(</span><em>fun</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.gpuscalar" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a small wrapper to simplify calling binary r = a op b kernels. It automates creation of the result array</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.guessGPUType">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">guessGPUType</code><span class="sig-paren">(</span><em>arg</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#guessGPUType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.guessGPUType" title="Permalink to this definition">¶</a></dt>
<dd><p>At the moment, this returns numpy.float32 for Python floats and
numpy.int32 for python integers, and is otherwise undefined</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.kernel">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">kernel</code><span class="sig-paren">(</span><em>header</em>, <em>code</em>, <em>other=None</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>This is my easy kernel wrapper. This function accepts a header ( the
list of arguments ), a body ( the core of the loop ), and optionally
a block of helper function code. The core loop should reference “tid” as
the thread index variable. The distribution of threads on the GPU is
automatically managed.</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.printKernel">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">printKernel</code><span class="sig-paren">(</span><em>code</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neurotools/gpu/cu/function.html#printKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neurotools.gpu.cu.function.printKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>This prints out a kernel source with line numbers</p>
</dd></dl>

<dl class="function">
<dt id="neurotools.gpu.cu.function.toGPUType">
<code class="descclassname">neurotools.gpu.cu.function.</code><code class="descname">toGPUType</code><span class="sig-paren">(</span><em>arg</em><span class="sig-paren">)</span><a class="headerlink" href="#neurotools.gpu.cu.function.toGPUType" title="Permalink to this definition">¶</a></dt>
<dd><p>A little wrapper to auto-cast floats/ints to respective numpy datatypes
for use on the GPU. This functionality probably exists elsewhere</p>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/neurotools.gpu.cu.function.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, M Rule.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/neurotools.gpu.cu.function.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>